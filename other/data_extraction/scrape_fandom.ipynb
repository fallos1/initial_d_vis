{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_episode_information(stage, act):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'}\n",
    "    url = \"https://initiald.fandom.com/wiki/\"\n",
    "\n",
    "    act_url = f\"{url}{stage}_-_Act_{act}\"\n",
    "    req = requests.get(act_url, headers=headers).text\n",
    "\n",
    "    info = {}\n",
    "    info[\"stage\"] = stage\n",
    "    info[\"act\"] = act\n",
    "\n",
    "    synopsis = req[req.find('<span class=\"mw-headline\" id=\"Synopsis\">'): req.find('<span class=\"mw-headline\" id=\"Plot\">')]\n",
    "    synopsis = BeautifulSoup(synopsis, \"html.parser\").find(\"p\").text\n",
    "\n",
    "    info[\"synopsis\"] = synopsis\n",
    "\n",
    "    plot = req[req.find('<span class=\"mw-headline\" id=\"Plot\">'): req.find('<span class=\"mw-headline\" id=\"Stats\">')]\n",
    "    plot = BeautifulSoup(plot, \"html.parser\").find_all(\"p\")\n",
    "    plot = \"\".join([i.text for i in plot])\n",
    "\n",
    "    info[\"plot\"] = plot\n",
    "\n",
    "    airdate = req[req.find('<span class=\"mw-headline\" id=\"Airdates\">'): req.find('<span id=\"Characters_(in_order_of_appearance)\">')]\n",
    "    airdate = BeautifulSoup(airdate, \"html.parser\").find(\"li\").text\n",
    "    \n",
    "    info[\"airdate\"] = airdate\n",
    "\n",
    "    characters = req[req.find('<span class=\"mw-headline\" id=\"Char'): req.find('<span class=\"mw-headline\" id=\"Cars\">'): ]\n",
    "    characters = BeautifulSoup(characters, \"html.parser\").find_all(\"li\")\n",
    "    characters = [i.text for i in characters]\n",
    "\n",
    "    info[\"characters\"] = characters\n",
    "\n",
    "    cars = req[req.find('<span class=\"mw-headline\" id=\"Cars\">'): req.find('<span class=\"mw-headline\" id=\"Music\">'): ]\n",
    "    cars = BeautifulSoup(cars, \"html.parser\").find_all(\"a\")\n",
    "    cars = [i.text for i in cars]\n",
    "\n",
    "    info[\"cars\"] = cars\n",
    "\n",
    "    music = req[req.find('<span class=\"mw-headline\" id=\"Music\">'): req.find('<span class=\"mw-headline\" id=\"Quotes\">'): ]\n",
    "    music = BeautifulSoup(music, \"html.parser\").find_all(\"a\")\n",
    "    music = [i.text for i in music]\n",
    "\n",
    "    info[\"music\"] = music\n",
    "\n",
    "    # quotes = req[req.find('<span class=\"mw-headline\" id=\"Quotes\">'): req.find('<span class=\"mw-headline\" id=\"Notes_.26_Trivia\">')]\n",
    "    # quotes = req[req.find('<span class=\"mw-headline\" id=\"Quot'): req.find('<span class=\"mw-headline\" id=\"N'): ]\n",
    "    # quotes = [i.text for i in quotes]\n",
    "\n",
    "    # info[\"quotes\"] = quotes\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'}\n",
    "url = \"https://initiald.fandom.com/wiki/\"\n",
    "stages = {\n",
    "    \"First_Stage\": 26,\n",
    "    \"Second_Stage\": 13,\n",
    "    \"Fourth_Stage\": 24,\n",
    "    \"Fifth_Stage\": 14,\n",
    "    \"Final_Stage\": 4,\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "for part in stages:\n",
    "    act = 1\n",
    "    while act <= stages[part]:\n",
    "        rows.append(get_episode_information(stage=part, act=act))\n",
    "        time.sleep(1.5)\n",
    "        print(f\"Done: {part} Act: {act}\")\n",
    "        act += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "initial_d = pd.DataFrame(rows)\n",
    "initial_d.head()\n",
    "initial_d.to_csv(\"fandom.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Car Counts\n",
    "initial_d[[\"stage\", \"act\", \"cars\"]].explode(\"cars\")[\"cars\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create adjacency matrix for cars and stages\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "G = nx.MultiDiGraph()\n",
    "\n",
    "for i in initial_d[\"stage\"].unique():\n",
    "    G.add_node(i)\n",
    "for i in initial_d[\"cars\"].unique():\n",
    "    G.add_node(i)\n",
    "\n",
    "for row in initial_d.itertuples():\n",
    "    G.add_edge(row.stage, row.cars)\n",
    "    G.add_edge(row.cars, row.stage)\n",
    "\n",
    "zeros = np.zeros((10, 10))\n",
    "top = np.concatenate([zeros, a], axis=1)\n",
    "bottom = np.concatenate([a, zeros], axis=1)\n",
    "np.concatenate([top, bottom], axis=0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cae83186340bc044668a88d7f7eedc3424a585e8e20f2c23d34c78a4f1a3c0b6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
