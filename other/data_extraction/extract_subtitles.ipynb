{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = {\n",
    "    \"Takumi\": [\"takumi\"],\n",
    "    \"Bunta\": [\"bunta\"],\n",
    "    \"Ryosuke\": [\"ryosuke\"],\n",
    "    \"Natsuki\": [\"natsuki\", \"mogi\"],\n",
    "    \"Iketani\": [\"iketani\"],\n",
    "    \"Keisuke\": [\"keisuke\"],\n",
    "    \"Mako\": [\"mako\", \"sato\"],\n",
    "    \"Itsuki\": [\"itsuki\"],\n",
    "    \"Takeshi\": [\"takeshi\", \"nakazato\"],\n",
    "    \"Kenji\": [\"kenji\"]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_word(x: str):\n",
    "    \"\"\"Strip unwanted characters from .ass files\n",
    "\n",
    "    Args:\n",
    "        x (str): word from ass file\n",
    "\n",
    "    Returns:\n",
    "        str: cleaned word\n",
    "    \"\"\"\n",
    "    x = x.lower()\n",
    "    remove = [\"{\\i1}\", \"{\\i0}\", \"=--\", \".\", \"'s\", \"!\", \",\", \"?\", '\"', \"'\", \"=\", \":\"\n",
    "    \"{\\\\an5\\\\pos(720107)}\", \"(\", \")\", \"{\\\\an5\\\\pos960175}\", \"{\\\\an5\\\\pos960107}\", \"--\"]\n",
    "    for i in remove:\n",
    "        x = x.replace(i, \"\")\n",
    "    x = x.replace(\"\\n\", \" \")\n",
    "    x = x.replace(\"\\r\", \" \")\n",
    "   \n",
    "    x = x.strip()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain all files from subtitles folder and sub-folders\n",
    "subtitles_dir = list(os.walk(\"subtitles\"))[0][1]\n",
    "subtitles = list(os.walk(\"subtitles\"))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "\n",
    "for sub in subtitles:\n",
    "    files = sub[2]\n",
    "    for i in files:\n",
    "        with open(f\"{sub[0]}\\\\{i}\") as f:\n",
    "            lines = f.readlines()[50:]\n",
    "            for line in lines:\n",
    "                line = line.split(\",,\")\n",
    "                line = line[1].split(\" \")\n",
    "                for word in line:\n",
    "                    word = clean_word(word)\n",
    "                    words.append((i, word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for bag of words\n",
    "bag_of_words = pd.DataFrame(words)\n",
    "\n",
    "bag_of_words = pd.DataFrame(words).replace(to_replace=[r\"\\\\t|\\\\n|\\\\r\", \"\\t|\\n|\\r\"], value=[\" \",\" \"], regex=True)\n",
    "bag_of_words.columns = [\"episode\", \"word\"]\n",
    "bag_of_words[\"word\"] = bag_of_words[\"word\"].str.split(\" \")\n",
    "bag_of_words[\"count\"] = 1\n",
    "bag_of_words = bag_of_words.explode(\"word\")\n",
    "bag_of_words = bag_of_words.groupby([\"episode\", \"word\"]).min()\n",
    "\n",
    "# List containing all words\n",
    "all_words = [i[1] for i in bag_of_words.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'my', 'value': 82},\n",
       " {'text': 'me', 'value': 82},\n",
       " {'text': 'be', 'value': 82},\n",
       " {'text': 'was', 'value': 82},\n",
       " {'text': 'like', 'value': 82},\n",
       " {'text': 'he', 'value': 82},\n",
       " {'text': 'up', 'value': 82},\n",
       " {'text': 'do', 'value': 82},\n",
       " {'text': 'and', 'value': 82},\n",
       " {'text': 'no', 'value': 82},\n",
       " {'text': 'to', 'value': 82},\n",
       " {'text': 'you', 'value': 82},\n",
       " {'text': 'are', 'value': 82},\n",
       " {'text': 'im', 'value': 82},\n",
       " {'text': 'this', 'value': 82},\n",
       " {'text': 'what', 'value': 82},\n",
       " {'text': 'for', 'value': 82},\n",
       " {'text': 'dont', 'value': 82},\n",
       " {'text': 'just', 'value': 82},\n",
       " {'text': 'on', 'value': 82},\n",
       " {'text': 'have', 'value': 82},\n",
       " {'text': 'not', 'value': 82},\n",
       " {'text': 'ill', 'value': 82},\n",
       " {'text': 'how', 'value': 82},\n",
       " {'text': 'but', 'value': 82},\n",
       " {'text': 'an', 'value': 82},\n",
       " {'text': 'about', 'value': 82},\n",
       " {'text': 'i', 'value': 82},\n",
       " {'text': 'think', 'value': 82},\n",
       " {'text': 'of', 'value': 82},\n",
       " {'text': 'right', 'value': 82},\n",
       " {'text': 'that', 'value': 82},\n",
       " {'text': 'your', 'value': 82},\n",
       " {'text': 'all', 'value': 82},\n",
       " {'text': 'if', 'value': 82},\n",
       " {'text': 'is', 'value': 82},\n",
       " {'text': 'can', 'value': 82},\n",
       " {'text': 'in', 'value': 82},\n",
       " {'text': 'it', 'value': 82},\n",
       " {'text': 'so', 'value': 82},\n",
       " {'text': 'with', 'value': 82},\n",
       " {'text': 'at', 'value': 82},\n",
       " {'text': 'the', 'value': 82},\n",
       " {'text': 'a', 'value': 82},\n",
       " {'text': 'go', 'value': 82},\n",
       " {'text': 'from', 'value': 81},\n",
       " {'text': 'one', 'value': 81},\n",
       " {'text': 'youre', 'value': 81},\n",
       " {'text': 'will', 'value': 81},\n",
       " {'text': 'by', 'value': 81},\n",
       " {'text': 'there', 'value': 81},\n",
       " {'text': 'we', 'value': 81},\n",
       " {'text': 'too', 'value': 81},\n",
       " {'text': 'know', 'value': 81},\n",
       " {'text': 'race', 'value': 81},\n",
       " {'text': 'cant', 'value': 81},\n",
       " {'text': 'time', 'value': 81},\n",
       " {'text': 'him', 'value': 81},\n",
       " {'text': 'out', 'value': 81},\n",
       " {'text': 'really', 'value': 80},\n",
       " {'text': 'way', 'value': 80},\n",
       " {'text': 'even', 'value': 80},\n",
       " {'text': 'let', 'value': 80},\n",
       " {'text': 'were', 'value': 80},\n",
       " {'text': 'has', 'value': 80},\n",
       " {'text': 'want', 'value': 80},\n",
       " {'text': 'when', 'value': 80},\n",
       " {'text': 'well', 'value': 79},\n",
       " {'text': 'here', 'value': 79},\n",
       " {'text': 'yeah', 'value': 79},\n",
       " {'text': 'his', 'value': 79},\n",
       " {'text': 'get', 'value': 79},\n",
       " {'text': 'ive', 'value': 79},\n",
       " {'text': 'see', 'value': 79},\n",
       " {'text': 'should', 'value': 78},\n",
       " {'text': 'wont', 'value': 78},\n",
       " {'text': 'now', 'value': 78},\n",
       " {'text': 'say', 'value': 78},\n",
       " {'text': 'good', 'value': 78},\n",
       " {'text': 'before', 'value': 78},\n",
       " {'text': 'could', 'value': 78},\n",
       " {'text': 'as', 'value': 78},\n",
       " {'text': 'more', 'value': 78},\n",
       " {'text': 'car', 'value': 78},\n",
       " {'text': 'sure', 'value': 78},\n",
       " {'text': 'come', 'value': 77},\n",
       " {'text': 'going', 'value': 77},\n",
       " {'text': 'why', 'value': 77},\n",
       " {'text': 'only', 'value': 77},\n",
       " {'text': 'got', 'value': 77},\n",
       " {'text': 'or', 'value': 77},\n",
       " {'text': 'would', 'value': 77},\n",
       " {'text': 'much', 'value': 76},\n",
       " {'text': 'didnt', 'value': 76},\n",
       " {'text': 'did', 'value': 76},\n",
       " {'text': 'who', 'value': 76},\n",
       " {'text': 'make', 'value': 76},\n",
       " {'text': 'they', 'value': 76},\n",
       " {'text': 'never', 'value': 75},\n",
       " {'text': 'fast', 'value': 75}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words = bag_of_words.reset_index()\n",
    "word_counts = bag_of_words[\"word\"].value_counts()[0:100].to_frame().reset_index()\n",
    "word_counts.columns = [\"text\", \"value\"]\n",
    "\n",
    "json.loads(word_counts.to_json(orient=\"table\", index=False))[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Takumi': 72,\n",
       " 'Bunta': 26,\n",
       " 'Ryosuke': 64,\n",
       " 'Natsuki': 31,\n",
       " 'Iketani': 47,\n",
       " 'Keisuke': 64,\n",
       " 'Mako': 20,\n",
       " 'Itsuki': 48,\n",
       " 'Takeshi': 30,\n",
       " 'Kenji': 29}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Character episode counts\n",
    "episode_counts = {}\n",
    "\n",
    "for char in characters:\n",
    "    for match in characters[char]:\n",
    "        count = word_counts.count(match)\n",
    "        if char in episode_counts.keys():\n",
    "            episode_counts[char] += count\n",
    "        else:\n",
    "            episode_counts[char] = count\n",
    "\n",
    "episode_counts"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cae83186340bc044668a88d7f7eedc3424a585e8e20f2c23d34c78a4f1a3c0b6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
